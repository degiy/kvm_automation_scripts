
================================================================================

A/ Install physique 3 serveurs e1,e2,e3
  - provisionning SLI
  - reception par EEI
  - mise en baie EEI
  - cablage reseau EEI + cable direct entre e1 et e2
  - installation OS debian par EEI
  
10.200.10.81    ebrox e1
10.200.10.82    edino e2
10.200.10.83    edopi e3

# cat /etc/debian_version  : 9.6 (stretch de 2017)
4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64 GNU/Linux
QEMU emulator version 2.8.1(Debian 1:2.8+dfsg-6+deb9u5)

disques :

   8        0  292935982 sda
   8        1     524288 sda1 (/boot)
   8        2  292410670 sda2 (/lvm)

  --- Logical volume ---
  LV Path                /dev/vg0/swap
  LV Size                8.00 GiB
  --- Logical volume ---
  LV Path                /dev/vg0/root
  LV Size                1.00 GiB
  --- Logical volume ---
  LV Path                /dev/vg0/var
  LV Size                4.00 GiB
  --- Logical volume ---
  LV Path                /dev/vg0/usr
  LV Size                8.00 GiB
  --- Logical volume ---
  LV Path                /dev/vg0/kvm
  LV Size                200.00 GiB
  --- Logical volume ---
  LV Path                /dev/vg0/home
  LV Size                6.00 GiB

réseau :

2: eno1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq master br0 state UP mode DEFAULT group default qlen 1000
3: eno2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000

3: eno2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether a0:d3:c1:fa:dc:61 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.2/24 brd 192.168.1.255 scope global eno2
    
3: eno2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether ac:16:2d:6e:bc:c5 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.1/24 brd 192.168.1.255 scope global eno2

internet :

ping proxy.eei.cena.fr     
PING tahsa.eei.cena.fr (10.196.32.91)

search eei.cena.fr
nameserver 10.196.32.89
nameserver 10.196.32.91

================================================================================

B/ Recup ISO + systeme de base machines hote + partage

- centos 7.6 et fedora server 28 et debian 9.6
dans : /kvm/iso et montage dans /mnt/iso

- export

/kvm/iso/fedora_server_28.iso   /mnt/iso/f28    iso9660 ro,relatime
/kvm/iso/centos_76.iso  /mnt/iso/c76    iso9660 ro,relatime
/kvm/iso/debian-9.6.0-amd64-DVD-1.iso   /mnt/iso/d96    iso9660 ro,relatime

- montage nfs via réseau eei sur 3 autres serveurs de ces 2 repertoires

#systemctl status nfs-kernel-server
dans /etc/exports
/kvm/iso        e2(ro,async,no_subtree_check,no_root_squash) e3(ro,async,no_subtree_check,no_root_squash)
/mnt/iso/c76 192.168.220.0/24(ro,async,no_subtree_check,no_root_squash) e2(ro,async,no_subtree_check,no_root_squash) e3(ro,async,no_subtree_check,no_root_squash)
/mnt/iso/d96 192.168.220.0/24(ro,async,no_subtree_check,no_root_squash) e2(ro,async,no_subtree_check,no_root_squash) e3(ro,async,no_subtree_check,no_root_squash)
/mnt/iso/f28 192.168.220.0/24(ro,async,no_subtree_check,no_root_squash) e2(ro,async,no_subtree_check,no_root_squash) e3(ro,async,no_subtree_check,no_root_squash)
/kvm/t  e2(rw,sync,no_subtree_check,no_root_squash) e3(rw,sync,no_subtree_check,no_root_squash) 192.168.220.0/24(rw,sync,no_subtree_check,no_root_squash)

exportfs -a

- import

mkdir /mnt/iso
mkdir /kvm/iso
mkdir /kvm/t  

ds /etc/fstab

e1:/kvm/iso /kvm/iso nfs ro
e1:/mnt/iso /mnt/iso nfs ro
e1:/kvm/t /kvm/t nfs rw

mount -a

================================================================================

C/ LANs partagés

- ménage eno2 de nicolas
ip a del 192.168.1.1/24 dev eno2
ip a del fe80::ae16:2dff:fe6e:bcc5/64 dev eno2

nom     abr  @ip          nm  vlanid
-------+---+-------------+---+----+
admin   ADM 192.168.220.0 /24  220
interne INT 192.168.221.0 /24  221
ingres  ING 192.168.222.0 /24  222
esb     ESB 192.168.223.0 /24  223
storage STO 192.168.224.0 /24  224

- bridge des 2 côtés, ex de /etc/interfaces

iface eno2.220 inet manual
 vlan-raw-device eno2

auto br_adm
iface br_adm inet static
 address 192.168.220.2/24
 bridge_ports eno2.220
 bridge_stp on
 brdige_maxwait 10

voir script (gen_...pl)

DNS ? à voir

================================================================================

D/ creation VM générique (@IP + cle + montage commun)

- autorisation de montage iso via nfs via admin

paramètres :
- passage ks par ajout de fichier à l'initrd (injection)
- ip (passage via ks)
- serveur ntp
- accès à l'iso (ip + path par nfs)
- compte root accessible depuis les machines d'admin (post-install)


================================================================================
E/ creation des interfaces supplémentaires des vms

- voir script gen.pl et utilisation des commandes virsh atach et montage qemu d'image qcow
- config ansible par groupe (tout, par serveur hote et par fonction transverse)



================================================================================
F/ VM gluster fs

- backup des vms de e1 sur e3 (pour reprendre rapidement à partir de l'image qemu)
  attention à conserver le sparse mode sur la copie via nfs
    cp --sparse=always sa.img /kvm/backups/
    1133900 -rw------- 1 root root 2148073472 Dec 28 14:08 sa.img

- test sur noeuds ds et vlan cluster entre les ds : sa & sb
- échanges de clés ssh entre machines, et test ssh (via vlan storage)

- récup des rpms sur http://mirror.centos.org/centos/7/storage/x86_64/gluster-3.12/

yum install ./glusterfs-server-3.12.15-1.el7.x86_64.rpm ./glusterfs-api-3.12.15-1.el7.x86_64.rpm ./glusterfs-libs-3.12.15-1.el7.x86_64.rpm ./glusterfs-client-xlators-3.12.15-1.el7.x86_64.rpm ./glusterfs-fuse-3.12.15-1.el7.x86_64.rpm ./glusterfs-cli-3.12.15-1.el7.x86_64.rpm ./glusterfs-3.12.15-1.el7.x86_64.rpm userspace-rcu-0.10.0-3.el7.x86_64.rpm

sur chaque serveur :

systemctl enable glusterd
systemctl start glusterd
systemctl status glusterd
gluster peer probe 192.168.227.142
gluster peer probe 192.168.224.142
# sans dernière ligne pas moyen de se connecter de l'autre réseau
mkdir /gv0

sur le premier :

gluster volume create gv0 replica 2 192.168.227.141:/gv0 192.168.227.142:/gv0 
gluster volume start gv0
gluster volume info

sur les 2 :

mkdir /mnt/gv0
mount -t glusterfs 192.168.227.141:/gv0 /mnt/gv0

[ tester que ça marche au reboot ]

================================================================================
G/ HA Proxy sur LB
(pas urgent)

================================================================================
H/ IP relogeable sur DMZ + clustering actif/passif avec pacemaker
sur dmz a & b :

# install de pcs (pacemaker)
yum install pcs -y

# choix d'un mdp (h)
passwd hacluster

# activation service
systemctl enable pcsd.service
systemctl start pcsd.service

# creation du cluster sur dmz a & b (commande que sur a), tester auth avec options -u user -p pw
pcs cluster auth dmz_a_cluster_dmz dmz_b_cluster_dmz
pcs cluster setup --start --name dmz_cluster dmz_a_cluster_dmz dmz_b_cluster_dmz
pcs cluster enable --all

# disable stonith
pcs property set stonith-enabled=false

# ip virtuelle (pour l'instant sur admin...)
pcs resource create virtual_ip ocf:heartbeat:IPaddr2 ip=192.168.220.100 iflabel=ifcl op monitor interval="5s" timeout="10s"

================================================================================
H/ ajout d'une interface sortante sur le réseau EEI pour les machines DMZ A & B
trouver une ip dispo
nmap -sn 10.200.10.0/24 | grep 10.200.10 | sed -e 's/^.*10.200.10.//' -e 's/^).*$//' | sort -n
- > 84 et 85 en fixe et 86 en flottante

virsh attach-interface da bridge br0 --model virtio --config
virsh domiflist da | grep br0

=> 52:54:00:fe:ff:ce   da

virsh attach-interface db bridge br0 --model virtio --config
virsh domiflist db | grep br0

=> 52:54:00:94:da:d2   db

cd /etc/sysconfig/network-scripts/
cat ifcfg-eth2 | sed -e 's/eth2/eth3/g' -e 's/^HWADDR.*$/HWADDR=52:54:00:fe:ff:ce/' -e 's/^IPADDR=.*$/IPADDR="10.200.10.84"/' > ifcfg-eth3
cat ifcfg-eth2 | sed -e 's/eth2/eth3/g' -e 's/^HWADDR.*$/HWADDR=52:54:00:94:da:d2/' -e 's/^IPADDR=.*$/IPADDR="10.200.10.85"/' > ifcfg-eth3

pcs resource delete virtual_ip
pcs resource create virtual_ip ocf:heartbeat:IPaddr2 ip=10.200.10.86 iflabel=ifcl op monitor interval="5s" timeout="10s"


================================================================================
I/ autour du reverse proxy

yum install haproxy -y

================================================================================
J/ autour d'un serveur web bidon sur esb

yum install perl-HTTP-Daemon -y
mkdir site
cat > site/index.html
<html>
response fuse A
</html>
^D

cat > http_server.pl


#!/usr/bin/perl

use HTTP::Daemon;
use HTTP::Status;
 
my $d = HTTP::Daemon->new(LocalPort => 80) || die;
print "Please contact me at: <URL:", $d->url, ">\n";
while (my $c = $d->accept) {
    while (my $r = $c->get_request) {
        if ($r->method eq 'GET' ) {
            $c->send_file_response("/root/site/".$r->uri->path);
        }
        else {
            $c->send_error(RC_FORBIDDEN)
        }
    }
    $c->close;
    undef($c);
}

chmod 755 ./http_server.pl 
